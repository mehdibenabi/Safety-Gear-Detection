{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":93136,"databundleVersionId":11091933,"sourceType":"competition"},{"sourceId":10744622,"sourceType":"datasetVersion","datasetId":6663305}],"dockerImageVersionId":30886,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install pandas numpy tensorflow matplotlib opencv-python scikit-learn \n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-13T22:12:01.616254Z","iopub.execute_input":"2025-02-13T22:12:01.616565Z","iopub.status.idle":"2025-02-13T22:12:05.396120Z","shell.execute_reply.started":"2025-02-13T22:12:01.616541Z","shell.execute_reply":"2025-02-13T22:12:05.390325Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\nRequirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.5)\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\nRequirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\nRequirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\nRequirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\nRequirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.19.1)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":84},{"cell_type":"code","source":"import os\nimport cv2\nimport shutil\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport random\n\nfrom shutil import copyfile\nfrom tensorflow.keras.layers import Conv2D,Add,MaxPooling2D, Dense, BatchNormalization,Input , Flatten\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T22:12:05.399073Z","iopub.execute_input":"2025-02-13T22:12:05.399532Z","iopub.status.idle":"2025-02-13T22:12:05.411614Z","shell.execute_reply.started":"2025-02-13T22:12:05.399491Z","shell.execute_reply":"2025-02-13T22:12:05.405911Z"}},"outputs":[],"execution_count":85},{"cell_type":"code","source":"import os\nimport pandas as pd\n\n\n# Define folder paths\nsource_folder = '/kaggle/input/draft-safety/train/train_safety'\n\ndf = pd.read_csv('/kaggle/input/draft-safety/train/train_annotation.csv')\nprint(df.head())\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T22:12:05.415729Z","iopub.execute_input":"2025-02-13T22:12:05.416290Z","iopub.status.idle":"2025-02-13T22:12:05.453687Z","shell.execute_reply.started":"2025-02-13T22:12:05.416234Z","shell.execute_reply":"2025-02-13T22:12:05.452210Z"}},"outputs":[{"name":"stdout","text":"  image_id                       labels\n0    img_0    person red_hat yellow_hat\n1    img_1              person blue_hat\n2    img_2       person vest yellow_hat\n3    img_3  person white_hat yellow_hat\n4    img_4    person red_hat yellow_hat\n","output_type":"stream"}],"execution_count":86},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\n# Define your possible labels\npossible_labels = ['person', 'vest', 'red_hat', 'blue_hat', 'white_hat', 'yellow_hat']\n\n# Assuming your DataFrame has a column 'labels' with string labels, e.g. \"person red_hat yellow_hat\"\ndf['labels'] = df['labels'].apply(lambda x: x.split(' '))\n\n# Create multi-hot encoded labels\nmlb = MultiLabelBinarizer(classes=possible_labels)\nencoded_labels = mlb.fit_transform(df['labels'])\n\n# Create a new DataFrame from these encoded labels\nencoded_df = pd.DataFrame(encoded_labels, columns=possible_labels)\n\n# Concatenate these new columns with the original DataFrame\ndf = pd.concat([df, encoded_df], axis=1)\n\n# Optionally, check dtypes to ensure they're numeric\nprint(df.dtypes)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T22:12:05.458495Z","iopub.execute_input":"2025-02-13T22:12:05.459144Z","iopub.status.idle":"2025-02-13T22:12:05.503555Z","shell.execute_reply.started":"2025-02-13T22:12:05.459026Z","shell.execute_reply":"2025-02-13T22:12:05.502007Z"}},"outputs":[{"name":"stdout","text":"image_id      object\nlabels        object\nperson         int64\nvest           int64\nred_hat        int64\nblue_hat       int64\nwhite_hat      int64\nyellow_hat     int64\ndtype: object\n","output_type":"stream"}],"execution_count":87},{"cell_type":"code","source":"import os\n\nmissing_images = [img for img in df['image_id'] if not os.path.exists('/kaggle/input/draft-safety/train/train_safety/' + img)]\nprint(f\"Images manquantes : {len(missing_images)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T22:12:05.505234Z","iopub.execute_input":"2025-02-13T22:12:05.505575Z","iopub.status.idle":"2025-02-13T22:12:05.560164Z","shell.execute_reply.started":"2025-02-13T22:12:05.505544Z","shell.execute_reply":"2025-02-13T22:12:05.557997Z"}},"outputs":[{"name":"stdout","text":"Images manquantes : 1860\n","output_type":"stream"}],"execution_count":88},{"cell_type":"code","source":"from PIL import Image\n\nimg_path = os.path.join('/kaggle/input/draft-safety/train/train_safety', df['image_id'].iloc[0])\ntry:\n    img = Image.open(img_path)\n    print(\"Image loaded successfully!\")\nexcept Exception as e:\n    print(\"Error loading image:\", e)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T22:15:49.200444Z","iopub.execute_input":"2025-02-13T22:15:49.200999Z","iopub.status.idle":"2025-02-13T22:15:49.212170Z","shell.execute_reply.started":"2025-02-13T22:15:49.200912Z","shell.execute_reply":"2025-02-13T22:15:49.210203Z"}},"outputs":[{"name":"stdout","text":"Error loading image: [Errno 2] No such file or directory: '/kaggle/input/draft-safety/train/train_safety/img_0.jpg.jpg.jpg'\n","output_type":"stream"}],"execution_count":96},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\n# Example: loading your CSV\ndf = pd.read_csv('/kaggle/input/draft-safety/train/train_annotation.csv')\n\n# Split the labels (assuming they're space-separated)\ndf['labels'] = df['labels'].apply(lambda x: x.split())\n\n# Define possible labels\npossible_labels = ['person', 'vest', 'blue_hat', 'red_hat', 'white_hat', 'yellow_hat']\n\n# Use MultiLabelBinarizer to create a binary matrix for the labels\nmlb = MultiLabelBinarizer(classes=possible_labels)\nencoded_labels = mlb.fit_transform(df['labels'])\n\n# Create a DataFrame with the encoded labels\nencoded_df = pd.DataFrame(encoded_labels, columns=possible_labels)\n\n# Merge the new columns with the original DataFrame\ndf = pd.concat([df, encoded_df], axis=1)\n\n# Check that the columns have been added\nprint(df.head())\nprint(df.columns)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T22:19:51.158139Z","iopub.execute_input":"2025-02-13T22:19:51.158545Z","iopub.status.idle":"2025-02-13T22:19:51.180542Z","shell.execute_reply.started":"2025-02-13T22:19:51.158512Z","shell.execute_reply":"2025-02-13T22:19:51.179432Z"}},"outputs":[{"name":"stdout","text":"  image_id                           labels  person  vest  blue_hat  red_hat  \\\n0    img_0    [person, red_hat, yellow_hat]       1     0         0        1   \n1    img_1               [person, blue_hat]       1     0         1        0   \n2    img_2       [person, vest, yellow_hat]       1     1         0        0   \n3    img_3  [person, white_hat, yellow_hat]       1     0         0        0   \n4    img_4    [person, red_hat, yellow_hat]       1     0         0        1   \n\n   white_hat  yellow_hat  \n0          0           1  \n1          0           0  \n2          0           1  \n3          1           1  \n4          0           1  \nIndex(['image_id', 'labels', 'person', 'vest', 'blue_hat', 'red_hat',\n       'white_hat', 'yellow_hat'],\n      dtype='object')\n","output_type":"stream"}],"execution_count":100},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimg_width, img_height = 224, 224  # adjust as needed\n\ndatagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n    validation_split=0.2\n)\n\n# Ensure the image filenames include the proper extension\ndf['image_id'] = df['image_id'].apply(lambda x: x if x.endswith('.jpg') else x + '.jpg')\n\ntrain_directory = '/kaggle/input/draft-safety/train/train_safety/'\n\ntrain_generator = datagen.flow_from_dataframe(\n    dataframe=df,\n    directory=train_directory,\n    x_col='image_id',\n    y_col=possible_labels,  # now these columns exist in the DataFrame\n    target_size=(img_width, img_height),\n    class_mode='raw',  # Use 'raw' for multi-label classification with numeric arrays\n    batch_size=32,\n    subset='training'\n)\n\nvalidation_generator = datagen.flow_from_dataframe(\n    dataframe=df,\n    directory=train_directory,\n    x_col='image_id',\n    y_col=possible_labels,\n    target_size=(img_width, img_height),\n    class_mode='raw',\n    batch_size=32,\n    subset='validation'\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T22:20:08.819299Z","iopub.execute_input":"2025-02-13T22:20:08.819597Z","iopub.status.idle":"2025-02-13T22:20:10.011493Z","shell.execute_reply.started":"2025-02-13T22:20:08.819571Z","shell.execute_reply":"2025-02-13T22:20:10.010552Z"}},"outputs":[{"name":"stdout","text":"Found 1488 validated image filenames.\nFound 372 validated image filenames.\n","output_type":"stream"}],"execution_count":101},{"cell_type":"code","source":"from tensorflow.keras import layers, models\nfrom tensorflow.keras.applications import EfficientNetB0\n\n# Define your image dimensions\nimg_width, img_height = 224, 224  # or your preferred dimensions\n\n# Load the base model without any weights\nbase_model = EfficientNetB0(input_shape=(img_width, img_height, 3), \n                             include_top=False, \n                             weights=None)\n# Load the weights from the local file (adjust the path as necessary)\nbase_model.load_weights('/kaggle/input/weights/efficientnetb0_notop.h5')\n\n# Freeze the base model if you want to use it for transfer learning\nbase_model.trainable = False\n\n# Build your full model\npossible_labels = ['person', 'vest', 'blue_hat', 'red_hat', 'white_hat', 'yellow_hat']\nmodel = models.Sequential([\n    base_model,\n    layers.GlobalAveragePooling2D(),\n    layers.Dense(128, activation='relu'),\n    layers.Dropout(0.5),\n    layers.Dense(len(possible_labels), activation='sigmoid')  # Sigmoid for multi-label classification\n])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T22:20:18.775587Z","iopub.execute_input":"2025-02-13T22:20:18.775931Z","iopub.status.idle":"2025-02-13T22:20:20.253066Z","shell.execute_reply.started":"2025-02-13T22:20:18.775900Z","shell.execute_reply":"2025-02-13T22:20:20.251633Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_4\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ efficientnetb0 (\u001b[38;5;33mFunctional\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)          │       \u001b[38;5;34m4,049,571\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ global_average_pooling2d_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m163,968\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │             \u001b[38;5;34m774\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ global_average_pooling2d_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">163,968</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,214,313\u001b[0m (16.08 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,214,313</span> (16.08 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m164,742\u001b[0m (643.52 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">164,742</span> (643.52 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,049,571\u001b[0m (15.45 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> (15.45 MB)\n</pre>\n"},"metadata":{}}],"execution_count":102},{"cell_type":"code","source":"history = model.fit(\n    train_generator,\n    validation_data=validation_generator,\n    epochs=20,\n    steps_per_epoch=train_generator.samples // 32,\n    validation_steps=validation_generator.samples // 32\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T22:20:24.929776Z","iopub.execute_input":"2025-02-13T22:20:24.930234Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2s/step - accuracy: 0.8802 - loss: 0.6040 - val_accuracy: 0.9886 - val_loss: 0.5179\nEpoch 2/20\n\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m46s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.5363","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.5363 - val_accuracy: 1.0000 - val_loss: 0.4934\nEpoch 3/20\n\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 0.9927 - loss: 0.5384 - val_accuracy: 0.9886 - val_loss: 0.5144\nEpoch 4/20\n\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.5052 - val_accuracy: 1.0000 - val_loss: 0.5489\nEpoch 5/20\n\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.9928 - loss: 0.5291 - val_accuracy: 0.9886 - val_loss: 0.5173\nEpoch 6/20\n\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9688 - loss: 0.5534 - val_accuracy: 1.0000 - val_loss: 0.5054\nEpoch 7/20\n\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 0.9919 - loss: 0.5305 - val_accuracy: 0.9886 - val_loss: 0.5178\nEpoch 8/20\n\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.4942 - val_accuracy: 1.0000 - val_loss: 0.4838\nEpoch 9/20\n\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.9931 - loss: 0.5262 - val_accuracy: 0.9886 - val_loss: 0.5141\nEpoch 10/20\n\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.5018 - val_accuracy: 1.0000 - val_loss: 0.5300\nEpoch 11/20\n\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 0.9932 - loss: 0.5220 - val_accuracy: 0.9886 - val_loss: 0.5185\nEpoch 12/20\n\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.5246 - val_accuracy: 1.0000 - val_loss: 0.4739\nEpoch 13/20\n\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.9921 - loss: 0.5204 - val_accuracy: 0.9886 - val_loss: 0.5151\nEpoch 14/20\n\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.5078 - val_accuracy: 1.0000 - val_loss: 0.5063\nEpoch 15/20\n\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 0.9950 - loss: 0.5209 - val_accuracy: 0.9886 - val_loss: 0.5154\nEpoch 16/20\n\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.5280 - val_accuracy: 1.0000 - val_loss: 0.5117\nEpoch 17/20\n\u001b[1m19/46\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.9924 - loss: 0.5166","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Create a test ImageDataGenerator\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n# Adjust the directory path if needed; ensure it points to your test folder\ntest_directory = '/kaggle/input/draft-safety/test_safety/test_safety'\n\n# Create the test generator\ntest_generator = test_datagen.flow_from_directory(\n    directory=test_directory,\n    target_size=(img_width, img_height),\n    class_mode=None,    # No labels for test set\n    batch_size=32,\n    shuffle=False\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Predict on the test set\npredictions = model.predict(test_generator, verbose=1)\n\n# Apply a threshold (commonly 0.5) to convert probabilities into binary predictions\npredicted_binary = (predictions > 0.5).astype(int)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert binary predictions to label lists\npredicted_labels_list = mlb.inverse_transform(predicted_binary)\n\n# For each image, join the labels into a single string (space-separated, for example)\npredicted_labels_str = [\" \".join(labels) if labels else \"none\" for labels in predicted_labels_list]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Extract filenames from the test generator.\n# Depending on how your test generator is set up, the filenames might include a folder path.\n# You might need to clean the filename to extract just the image ID.\nfilenames = test_generator.filenames\n\n# If the filenames include subdirectories, you can remove them.\n# For example, if filenames look like 'test/img_0.jpg', you can extract the basename:\nfilenames = [fname.split('/')[-1] for fname in filenames]\n\n# Create the submission DataFrame\nsubmission_df = pd.DataFrame({\n    'image_id': filenames,\n    'labels': predicted_labels_str\n})\n\n# Check the first few rows of your submission file\nprint(submission_df.head())\n# Save the submission file in the Kaggle output directory\nsubmission_df.to_csv('/kaggle/working/submission.csv', index=False)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}